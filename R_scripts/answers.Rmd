---
title: "KPI Suggestions"
author: "Trenton Pulsipher"
date: "9/25/2018"
output: html_document
---

```{r setup, echo = F, error = F, waring = F, message = F}

```

## Questions


##### 1. A director in the missionary department has asked the analytics team to produce suggested key indicator goals for a specific area and missions. Using the attached dataset determine how you might suggest approaching the best key indicator goals for these missions. Share your code (R, Python, or Julia) as well as an executive summary (how would you present this to a director).

Approaches: I might propose three options here, starting from simpliest to more complex. 
  
  1. Take a four week moving average of each mission's KPI and then increase it 10%. For example, if a mission had baptisms for the previous four weeks of 5, 15, 12, and 8 then their four week moving average would be 10 and the 10% increase would become a goal of 11 baptisms for the following week. That may seem too low given they recently baptized 15 and 12 people a week respectively, however as they meet their goals each week their proposed goal of 10% above the moving average would continue to increase and demand additional effort. The parameters four and 10% are quite arbitrary and one could quickly build a shiny app in R to allow anyone to play with those two parameters to determine their optimal/desired setting. Historical analysis could also be employed to determine how often each mission would have met their goals under those parameter settings.
  
  2. Fit a time-series model to each mission's KPI and forecast the next several weeks (2-4 weeks out). Given the nature of the data one could develop a more sophisticated time-series method and apply it across all mission KPIs. Time-series modeling may be best as part of an ensemble method, but that over complicates the approach. Much of the same checks, concerns, and creativity required for evaluating a machine learning model based method would apply to a time-series based method.
  
  3. Allow a machine learning model to provide the prediction and goal. This one is trickier. Extremely popular now machine learning is no longer difficult and can provide an excellent prediction. One would need to develop rules around that prediction for reasonableness and to adjust for when those predictions are much lower than the desired outcome. An example of a situation where a rule would help, we see many missions revert to a more healthy/reasonable pattern in their KPIs after a change in mission presidents (maybe due to an interpretation of the KPI or a change in focus). While there are many reasons for this it does require some creativity in building models to allow for that flexibility. Given a stretch goal is desired the model could easily predict continued drops in their KPI but one would want to adjust those drops to be as shallow (not steep) as possible. 
  This may be a more intense effort than desired but I feel like these complex, black box methods are available and can facilitate some interesting outcomes if studied sufficiently. Ask me about how we implemented a customer saving program by identifying those at risk of attrition on one of our products using only one time-series of daily activity counts.

Another approach may involve an overall score for each mission (think of it as a health indicator) calculated based on each misssion's KPIs. Such a method would be easily calculated and any of the goal setting proposals above could apply. The difficulty would be building concensus around the weights of the various KPIs which determine the calculated overall score.

Notes: I struggled with this a little. Elder Ballard maintains goals should be simple and straightforward, which may be difficult to demonstrate when leveraging a data driven approach. Sophistication in the model or approach is often unnessary, however, I personally would want to try all three proposed approaches to some extent for comparison. Developing the code would be the most difficult part, but once developed would allow for historical analysis and validation likely generating a robust model and known limitations. Definitely a fun problem with very attainable solutions.


##### 2. How would you assess the performance of these missions? Share your code (R, Python, or Julia) as well as an executive summary (how would you present this to a director).

I feel my [initial assessment](notes-thoughts.html) covers my approach to evaluating mission performance. For department internal purposes a scorecard could be calculated allowing for quick discovery of which missions may benefit from additional attention, training, or intervention. Tableau, or other BI tools, facilitate data discovery via both summary and drillable detailed information. Such dashboards likely provide a sufficient medium to share performance related reporting.
Could include a table of performance assessment by Mission and KPI. Performance assessment isn't always simple given the nature of changing mission presidents, the number of missionaries, mission boundaries, and other factors (age change, more sisters, local events/politics).


##### 3. How would you assess the performance of these mission presidents? Share your code (R, Python, or Julia) as well as an executive summary (how would you present this to a director).

If changes in mission presidents were the only thing changing in missions then addressing mission president performance would be easy. Even with so many other changes solutions are possible. I struggle a little knowing that often exceptions exist and major swings in KPIs aren't always as good or as bad as intially perceived. Otherwise some simple historical analysis to determine a general baseline would help establish performance and goals for each mission president. Again I would look to the standard (already produced) KPI report to address their performance and adjust any assessment if needed based on previous mission presidents KPI behaviors.
 
see [mission president performance interactive report](missionPresidentPerformance.html)


##### 4. How would you assess the effect of missionary count on key indicators? Share your code (R, Python, or Julia) as well as an executive summary (how would you present this to a director).

scatterplot
